{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just stick some data there\n",
    "with open('email_addresses.txt', 'w') as f:\n",
    "    f.write(\"joelgrus@gmail.com\\n\")\n",
    "    f.write(\"joel@m.datasciencester.com\\n\")\n",
    "    f.write(\"joelgrus@m.datasciencester.com\\n\")\n",
    "\n",
    "def get_domain(email_address: str) -> str:\n",
    "    \"\"\"Split on '@' and return the last piece\"\"\"\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "\n",
    "# a couple of tests\n",
    "assert get_domain('joelgrus@gmail.com') == 'gmail.com'\n",
    "assert get_domain('joel@m.datasciencester.com') == 'm.datasciencester.com'\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if \"@\" in line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tab_delimited_stock_prices.txt', 'w') as f:\n",
    "    f.write(\"\"\"6/20/2014\\tAAPL\\t90.91\n",
    "6/20/2014\\tMSFT\\t41.68\n",
    "6/20/2014\\tFB\\t64.5\n",
    "6/19/2014\\tAAPL\\t91.86\n",
    "6/19/2014\\tMSFT\\t41.51\n",
    "6/19/2014\\tFB\\t64.34\n",
    "\"\"\")\n",
    "\n",
    "def process(date: str, symbol: str, closing_price: float) -> None:\n",
    "    # Imaginge that this function actually does something.\n",
    "    assert closing_price > 0.0\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('tab_delimited_stock_prices.txt') as f:\n",
    "    tab_reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in tab_reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        process(date, symbol, closing_price)\n",
    "\n",
    "\n",
    "with open('colon_delimited_stock_prices.txt', 'w') as f:\n",
    "    f.write(\"\"\"date:symbol:closing_price\n",
    "6/20/2014:AAPL:90.91\n",
    "6/20/2014:MSFT:41.68\n",
    "6/20/2014:FB:64.5\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('colon_delimited_stock_prices.txt') as f:\n",
    "    colon_reader = csv.DictReader(f, delimiter=':')\n",
    "    for dict_row in colon_reader:\n",
    "        date = dict_row[\"date\"]\n",
    "        symbol = dict_row[\"symbol\"]\n",
    "        closing_price = float(dict_row[\"closing_price\"])\n",
    "        process(date, symbol, closing_price)\n",
    "\n",
    "todays_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5 }\n",
    "\n",
    "with open('comma_delimited_stock_prices.txt', 'w') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in todays_prices.items():\n",
    "        csv_writer.writerow([stock, price])\n",
    "\n",
    "results = [[\"test1\", \"success\", \"Monday\"],\n",
    "           [\"test2\", \"success, kind of\", \"Tuesday\"],\n",
    "           [\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
    "           [\"test4\", \"failure, utter\", \"Thursday\"]]\n",
    "\n",
    "# don't do this!\n",
    "with open('bad_csv.txt', 'w') as f:\n",
    "    for row in results:\n",
    "        f.write(\",\".join(map(str, row))) # might have too many commas in it!\n",
    "        f.write(\"\\n\")                    # row might have newlines as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Webスクレイピング\n",
    "### 9.3.1 HTMLとその解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Science Book',\n",
       " 'author': 'Joel Grus',\n",
       " 'publicationYear': 2019,\n",
       " 'topics': ['data', 'science', 'data science']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# I put the relevant HTML file on GitHub. In order to fit\n",
    "# the URL in the book I had to split it across two lines.\n",
    "# Recall that whitespace-separated strings get concatenated.\n",
    "\n",
    "# https://raw.githubusercontent.com/joelgrus/data/master/getting-data.html\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/\"\n",
    "       \"joelgrus/data/master/getting-data.html\")\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "first_paragraph = soup.find('p')        # or just soup.p\n",
    "\n",
    "\n",
    "assert str(soup.find('p')) == '<p id=\"p1\">This is the first paragraph.</p>'\n",
    "\n",
    "# textプロパティを通して、タグの文字列部分を取り出し\n",
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_words = soup.p.text.split()\n",
    "\n",
    "\n",
    "assert first_paragraph_words == ['This', 'is', 'the', 'first', 'paragraph.']\n",
    "\n",
    "# 属性へのアクセス\n",
    "first_paragraph_id = soup.p['id']       # raises KeyError if no 'id'\n",
    "first_paragraph_id2 = soup.p.get('id')  # returns None if no 'id'\n",
    "\n",
    "\n",
    "assert first_paragraph_id == first_paragraph_id2 == 'p1'\n",
    "\n",
    "# 複数のタグを一度に取り出す\n",
    "all_paragraphs = soup.find_all('p')  # or just soup('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "\n",
    "\n",
    "assert len(all_paragraphs) == 2\n",
    "assert len(paragraphs_with_ids) == 1\n",
    "\n",
    "# 特定のクラスに属するタグが目的となる場合\n",
    "important_paragraphs = soup('p', {'class' : 'important'})\n",
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs3 = [p for p in soup('p')\n",
    "                         if 'important' in p.get('class', [])]\n",
    "\n",
    "\n",
    "assert important_paragraphs == important_paragraphs2 == important_paragraphs3\n",
    "assert len(important_paragraphs) == 1\n",
    "\n",
    "# warning, will return the same span multiple times\n",
    "# if it sits inside multiple divs\n",
    "# be more clever if that's the case\n",
    "spans_inside_divs = [span\n",
    "                     for div in soup('div')     # for each <div> on the page\n",
    "                     for span in div('span')]   # find each <span> inside it\n",
    "\n",
    "\n",
    "assert len(spans_inside_divs) == 3\n",
    "\n",
    "\n",
    "def paragraph_mentions(text: str, keyword: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if a <p> inside the text mentions {keyword}\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'html5lib')\n",
    "    paragraphs = [p.get_text() for p in soup('p')]\n",
    "\n",
    "    return any(keyword.lower() in paragraph.lower()\n",
    "               for paragraph in paragraphs)\n",
    "\n",
    "text = \"\"\"<body><h1>Facebook</h1><p>Twitter</p>\"\"\"\n",
    "assert paragraph_mentions(text, \"twitter\")       # is inside a <p>\n",
    "assert not paragraph_mentions(text, \"facebook\")  # not inside a <p>\n",
    "\n",
    "{ \"title\" : \"Data Science Book\",\n",
    "  \"author\" : \"Joel Grus\",\n",
    "  \"publicationYear\" : 2019,\n",
    "  \"topics\" : [ \"data\", \"science\", \"data science\"] }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.2 事例：議会の行動に目を光らせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "874\n",
      "437\n",
      "{'https://jayapal.house.gov/category/press-releases/'}\n",
      "after sampling, left with ['https://mucarsel-powell.house.gov', 'https://francisrooney.house.gov', 'https://dennyheck.house.gov', 'https://stefanik.house.gov/', 'https://langevin.house.gov']\n",
      "https://mucarsel-powell.house.gov: {'/news/documentquery.aspx?DocumentTypeID=27'}\n",
      "https://francisrooney.house.gov: {'/news/documentquery.aspx?DocumentTypeID=27'}\n",
      "https://dennyheck.house.gov: {'/media-center/press-releases'}\n",
      "https://stefanik.house.gov/: {'/media-center/press-releases'}\n",
      "https://langevin.house.gov: {'/press-releases'}\n"
     ]
    }
   ],
   "source": [
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    url = \"https://www.house.gov/representatives\"\n",
    "    text = requests.get(url).text\n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "    \n",
    "    all_urls = [a['href']\n",
    "                for a in soup('a')\n",
    "                if a.has_attr('href')]\n",
    "    \n",
    "    print(len(all_urls))  # 965 for me, way too many\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    # Must start with http:// or https://\n",
    "    # Must end with .house.gov or .house.gov/\n",
    "    regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
    "    \n",
    "    # Let's write some tests!\n",
    "    assert re.match(regex, \"http://joel.house.gov\")\n",
    "    assert re.match(regex, \"https://joel.house.gov\")\n",
    "    assert re.match(regex, \"http://joel.house.gov/\")\n",
    "    assert re.match(regex, \"https://joel.house.gov/\")\n",
    "    assert not re.match(regex, \"joel.house.gov\")\n",
    "    assert not re.match(regex, \"http://joel.house.com\")\n",
    "    assert not re.match(regex, \"https://joel.house.gov/biography\")\n",
    "    \n",
    "        # And now apply\n",
    "    good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "    \n",
    "    print(len(good_urls))  # still 862 for me\n",
    "    \n",
    "    \n",
    "    num_original_good_urls = len(good_urls)\n",
    "    \n",
    "    good_urls = list(set(good_urls))\n",
    "    \n",
    "    print(len(good_urls))  # only 431 for me\n",
    "    \n",
    "    \n",
    "    assert len(good_urls) < num_original_good_urls\n",
    "    \n",
    "    html = requests.get('https://jayapal.house.gov').text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    \n",
    "    # Use a set because the links might appear multiple times.\n",
    "    links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "    \n",
    "    print(links) # {'/media/press-releases'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # I don't want this file to scrape all 400+ websites every time it runs.\n",
    "    # So I'm going to randomly throw out most of the urls.\n",
    "    # The code in the book doesn't do this.\n",
    "    import random\n",
    "    good_urls = random.sample(good_urls, 5)\n",
    "    print(f\"after sampling, left with {good_urls}\")\n",
    "    \n",
    "    from typing import Dict, Set\n",
    "    \n",
    "    press_releases: Dict[str, Set[str]] = {}\n",
    "    \n",
    "    for house_url in good_urls:\n",
    "        html = requests.get(house_url).text\n",
    "        soup = BeautifulSoup(html, 'html5lib')\n",
    "        pr_links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "        print(f\"{house_url}: {pr_links}\")\n",
    "        press_releases[house_url] = pr_links\n",
    "    \n",
    "    for house_url, pr_links in press_releases.items():\n",
    "        for pr_link in pr_links:\n",
    "            url = f\"{house_url}/{pr_link}\"\n",
    "            text = requests.get(url).text\n",
    "    \n",
    "            if paragraph_mentions(text, 'data'):\n",
    "                print(f\"{house_url}\")\n",
    "                break  # done with this house_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 APIを使う\n",
    "### 9.4.1 JSONとXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                  \"author\" : \"Joel Grus\",\n",
    "                  \"publicationYear\" : 2019,\n",
    "                  \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "\n",
    "# parse the JSON to create a Python dict\n",
    "deserialized = json.loads(serialized)\n",
    "assert deserialized[\"publicationYear\"] == 2019\n",
    "assert \"data science\" in deserialized[\"topics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4.2 認証が不要なAPIを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 284240723,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkyODQyNDA3MjM=',\n",
       "  'name': 'cookbook-2nd-code',\n",
       "  'full_name': 'deepkick/cookbook-2nd-code',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'deepkick',\n",
       "   'id': 1021024,\n",
       "   'node_id': 'MDQ6VXNlcjEwMjEwMjQ=',\n",
       "   'avatar_url': 'https://avatars0.githubusercontent.com/u/1021024?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/deepkick',\n",
       "   'html_url': 'https://github.com/deepkick',\n",
       "   'followers_url': 'https://api.github.com/users/deepkick/followers',\n",
       "   'following_url': 'https://api.github.com/users/deepkick/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/deepkick/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/deepkick/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/deepkick/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/deepkick/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/deepkick/repos',\n",
       "   'events_url': 'https://api.github.com/users/deepkick/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/deepkick/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/deepkick/cookbook-2nd-code',\n",
       "  'description': 'Code of the IPython Cookbook, Second Edition, by Cyrille Rossant, Packt Publishing 2018 [read-only repository]',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code',\n",
       "  'forks_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/deepkick/cookbook-2nd-code/deployments',\n",
       "  'created_at': '2020-08-01T10:46:03Z',\n",
       "  'updated_at': '2020-08-02T01:43:35Z',\n",
       "  'pushed_at': '2020-08-02T01:43:33Z',\n",
       "  'git_url': 'git://github.com/deepkick/cookbook-2nd-code.git',\n",
       "  'ssh_url': 'git@github.com:deepkick/cookbook-2nd-code.git',\n",
       "  'clone_url': 'https://github.com/deepkick/cookbook-2nd-code.git',\n",
       "  'svn_url': 'https://github.com/deepkick/cookbook-2nd-code',\n",
       "  'homepage': '',\n",
       "  'size': 46770,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': 'Jupyter Notebook',\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': False,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': {'key': 'mit',\n",
       "   'name': 'MIT License',\n",
       "   'spdx_id': 'MIT',\n",
       "   'url': 'https://api.github.com/licenses/mit',\n",
       "   'node_id': 'MDc6TGljZW5zZTEz'},\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'master'},\n",
       " {'id': 175031178,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkxNzUwMzExNzg=',\n",
       "  'name': 'automatestuff-ja',\n",
       "  'full_name': 'deepkick/automatestuff-ja',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'deepkick',\n",
       "   'id': 1021024,\n",
       "   'node_id': 'MDQ6VXNlcjEwMjEwMjQ=',\n",
       "   'avatar_url': 'https://avatars0.githubusercontent.com/u/1021024?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/deepkick',\n",
       "   'html_url': 'https://github.com/deepkick',\n",
       "   'followers_url': 'https://api.github.com/users/deepkick/followers',\n",
       "   'following_url': 'https://api.github.com/users/deepkick/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/deepkick/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/deepkick/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/deepkick/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/deepkick/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/deepkick/repos',\n",
       "   'events_url': 'https://api.github.com/users/deepkick/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/deepkick/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/deepkick/automatestuff-ja',\n",
       "  'description': '『退屈なことはPythonにやらせよう』のリポジトリ',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/deepkick/automatestuff-ja',\n",
       "  'forks_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/deepkick/automatestuff-ja/deployments',\n",
       "  'created_at': '2019-03-11T15:37:21Z',\n",
       "  'updated_at': '2020-08-01T06:40:15Z',\n",
       "  'pushed_at': '2020-08-01T06:40:12Z',\n",
       "  'git_url': 'git://github.com/deepkick/automatestuff-ja.git',\n",
       "  'ssh_url': 'git@github.com:deepkick/automatestuff-ja.git',\n",
       "  'clone_url': 'https://github.com/deepkick/automatestuff-ja.git',\n",
       "  'svn_url': 'https://github.com/deepkick/automatestuff-ja',\n",
       "  'homepage': 'https://www.oreilly.co.jp/books/9784873117782/',\n",
       "  'size': 15770,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': 'Python',\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': True,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': None,\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'master'},\n",
       " {'id': 282261378,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkyODIyNjEzNzg=',\n",
       "  'name': 'data-science-from-scratch',\n",
       "  'full_name': 'deepkick/data-science-from-scratch',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'deepkick',\n",
       "   'id': 1021024,\n",
       "   'node_id': 'MDQ6VXNlcjEwMjEwMjQ=',\n",
       "   'avatar_url': 'https://avatars0.githubusercontent.com/u/1021024?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/deepkick',\n",
       "   'html_url': 'https://github.com/deepkick',\n",
       "   'followers_url': 'https://api.github.com/users/deepkick/followers',\n",
       "   'following_url': 'https://api.github.com/users/deepkick/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/deepkick/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/deepkick/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/deepkick/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/deepkick/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/deepkick/repos',\n",
       "   'events_url': 'https://api.github.com/users/deepkick/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/deepkick/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/deepkick/data-science-from-scratch',\n",
       "  'description': 'code for Data Science From Scratch book',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/deepkick/data-science-from-scratch',\n",
       "  'forks_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/deepkick/data-science-from-scratch/deployments',\n",
       "  'created_at': '2020-07-24T15:57:57Z',\n",
       "  'updated_at': '2020-07-31T01:13:06Z',\n",
       "  'pushed_at': '2020-07-31T01:12:59Z',\n",
       "  'git_url': 'git://github.com/deepkick/data-science-from-scratch.git',\n",
       "  'ssh_url': 'git@github.com:deepkick/data-science-from-scratch.git',\n",
       "  'clone_url': 'https://github.com/deepkick/data-science-from-scratch.git',\n",
       "  'svn_url': 'https://github.com/deepkick/data-science-from-scratch',\n",
       "  'homepage': None,\n",
       "  'size': 1124,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': 'Jupyter Notebook',\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': True,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': {'key': 'mit',\n",
       "   'name': 'MIT License',\n",
       "   'spdx_id': 'MIT',\n",
       "   'url': 'https://api.github.com/licenses/mit',\n",
       "   'node_id': 'MDc6TGljZW5zZTEz'},\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'master'},\n",
       " {'id': 255513563,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkyNTU1MTM1NjM=',\n",
       "  'name': 'COVID-19',\n",
       "  'full_name': 'deepkick/COVID-19',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'deepkick',\n",
       "   'id': 1021024,\n",
       "   'node_id': 'MDQ6VXNlcjEwMjEwMjQ=',\n",
       "   'avatar_url': 'https://avatars0.githubusercontent.com/u/1021024?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/deepkick',\n",
       "   'html_url': 'https://github.com/deepkick',\n",
       "   'followers_url': 'https://api.github.com/users/deepkick/followers',\n",
       "   'following_url': 'https://api.github.com/users/deepkick/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/deepkick/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/deepkick/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/deepkick/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/deepkick/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/deepkick/repos',\n",
       "   'events_url': 'https://api.github.com/users/deepkick/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/deepkick/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/deepkick/COVID-19',\n",
       "  'description': 'Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/deepkick/COVID-19',\n",
       "  'forks_url': 'https://api.github.com/repos/deepkick/COVID-19/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/deepkick/COVID-19/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/deepkick/COVID-19/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/deepkick/COVID-19/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/deepkick/COVID-19/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/deepkick/COVID-19/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/deepkick/COVID-19/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/deepkick/COVID-19/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/deepkick/COVID-19/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/deepkick/COVID-19/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/deepkick/COVID-19/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/deepkick/COVID-19/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/deepkick/COVID-19/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/deepkick/COVID-19/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/deepkick/COVID-19/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/deepkick/COVID-19/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/deepkick/COVID-19/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/deepkick/COVID-19/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/deepkick/COVID-19/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/deepkick/COVID-19/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/deepkick/COVID-19/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/deepkick/COVID-19/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/deepkick/COVID-19/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/deepkick/COVID-19/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/deepkick/COVID-19/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/deepkick/COVID-19/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/deepkick/COVID-19/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/deepkick/COVID-19/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/deepkick/COVID-19/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/deepkick/COVID-19/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/deepkick/COVID-19/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/deepkick/COVID-19/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/deepkick/COVID-19/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/deepkick/COVID-19/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/deepkick/COVID-19/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/deepkick/COVID-19/deployments',\n",
       "  'created_at': '2020-04-14T04:54:54Z',\n",
       "  'updated_at': '2020-05-13T03:28:00Z',\n",
       "  'pushed_at': '2020-05-13T03:27:54Z',\n",
       "  'git_url': 'git://github.com/deepkick/COVID-19.git',\n",
       "  'ssh_url': 'git@github.com:deepkick/COVID-19.git',\n",
       "  'clone_url': 'https://github.com/deepkick/COVID-19.git',\n",
       "  'svn_url': 'https://github.com/deepkick/COVID-19',\n",
       "  'homepage': 'https://systems.jhu.edu/research/public-health/ncov/',\n",
       "  'size': 93246,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': None,\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': True,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': None,\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'master'},\n",
       " {'id': 258767265,\n",
       "  'node_id': 'MDEwOlJlcG9zaXRvcnkyNTg3NjcyNjU=',\n",
       "  'name': 'firefox-ios',\n",
       "  'full_name': 'deepkick/firefox-ios',\n",
       "  'private': False,\n",
       "  'owner': {'login': 'deepkick',\n",
       "   'id': 1021024,\n",
       "   'node_id': 'MDQ6VXNlcjEwMjEwMjQ=',\n",
       "   'avatar_url': 'https://avatars0.githubusercontent.com/u/1021024?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/deepkick',\n",
       "   'html_url': 'https://github.com/deepkick',\n",
       "   'followers_url': 'https://api.github.com/users/deepkick/followers',\n",
       "   'following_url': 'https://api.github.com/users/deepkick/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/deepkick/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/deepkick/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/deepkick/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/deepkick/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/deepkick/repos',\n",
       "   'events_url': 'https://api.github.com/users/deepkick/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/deepkick/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'html_url': 'https://github.com/deepkick/firefox-ios',\n",
       "  'description': 'Firefox for iOS',\n",
       "  'fork': True,\n",
       "  'url': 'https://api.github.com/repos/deepkick/firefox-ios',\n",
       "  'forks_url': 'https://api.github.com/repos/deepkick/firefox-ios/forks',\n",
       "  'keys_url': 'https://api.github.com/repos/deepkick/firefox-ios/keys{/key_id}',\n",
       "  'collaborators_url': 'https://api.github.com/repos/deepkick/firefox-ios/collaborators{/collaborator}',\n",
       "  'teams_url': 'https://api.github.com/repos/deepkick/firefox-ios/teams',\n",
       "  'hooks_url': 'https://api.github.com/repos/deepkick/firefox-ios/hooks',\n",
       "  'issue_events_url': 'https://api.github.com/repos/deepkick/firefox-ios/issues/events{/number}',\n",
       "  'events_url': 'https://api.github.com/repos/deepkick/firefox-ios/events',\n",
       "  'assignees_url': 'https://api.github.com/repos/deepkick/firefox-ios/assignees{/user}',\n",
       "  'branches_url': 'https://api.github.com/repos/deepkick/firefox-ios/branches{/branch}',\n",
       "  'tags_url': 'https://api.github.com/repos/deepkick/firefox-ios/tags',\n",
       "  'blobs_url': 'https://api.github.com/repos/deepkick/firefox-ios/git/blobs{/sha}',\n",
       "  'git_tags_url': 'https://api.github.com/repos/deepkick/firefox-ios/git/tags{/sha}',\n",
       "  'git_refs_url': 'https://api.github.com/repos/deepkick/firefox-ios/git/refs{/sha}',\n",
       "  'trees_url': 'https://api.github.com/repos/deepkick/firefox-ios/git/trees{/sha}',\n",
       "  'statuses_url': 'https://api.github.com/repos/deepkick/firefox-ios/statuses/{sha}',\n",
       "  'languages_url': 'https://api.github.com/repos/deepkick/firefox-ios/languages',\n",
       "  'stargazers_url': 'https://api.github.com/repos/deepkick/firefox-ios/stargazers',\n",
       "  'contributors_url': 'https://api.github.com/repos/deepkick/firefox-ios/contributors',\n",
       "  'subscribers_url': 'https://api.github.com/repos/deepkick/firefox-ios/subscribers',\n",
       "  'subscription_url': 'https://api.github.com/repos/deepkick/firefox-ios/subscription',\n",
       "  'commits_url': 'https://api.github.com/repos/deepkick/firefox-ios/commits{/sha}',\n",
       "  'git_commits_url': 'https://api.github.com/repos/deepkick/firefox-ios/git/commits{/sha}',\n",
       "  'comments_url': 'https://api.github.com/repos/deepkick/firefox-ios/comments{/number}',\n",
       "  'issue_comment_url': 'https://api.github.com/repos/deepkick/firefox-ios/issues/comments{/number}',\n",
       "  'contents_url': 'https://api.github.com/repos/deepkick/firefox-ios/contents/{+path}',\n",
       "  'compare_url': 'https://api.github.com/repos/deepkick/firefox-ios/compare/{base}...{head}',\n",
       "  'merges_url': 'https://api.github.com/repos/deepkick/firefox-ios/merges',\n",
       "  'archive_url': 'https://api.github.com/repos/deepkick/firefox-ios/{archive_format}{/ref}',\n",
       "  'downloads_url': 'https://api.github.com/repos/deepkick/firefox-ios/downloads',\n",
       "  'issues_url': 'https://api.github.com/repos/deepkick/firefox-ios/issues{/number}',\n",
       "  'pulls_url': 'https://api.github.com/repos/deepkick/firefox-ios/pulls{/number}',\n",
       "  'milestones_url': 'https://api.github.com/repos/deepkick/firefox-ios/milestones{/number}',\n",
       "  'notifications_url': 'https://api.github.com/repos/deepkick/firefox-ios/notifications{?since,all,participating}',\n",
       "  'labels_url': 'https://api.github.com/repos/deepkick/firefox-ios/labels{/name}',\n",
       "  'releases_url': 'https://api.github.com/repos/deepkick/firefox-ios/releases{/id}',\n",
       "  'deployments_url': 'https://api.github.com/repos/deepkick/firefox-ios/deployments',\n",
       "  'created_at': '2020-04-25T12:13:19Z',\n",
       "  'updated_at': '2020-04-25T12:13:21Z',\n",
       "  'pushed_at': '2020-04-24T17:15:21Z',\n",
       "  'git_url': 'git://github.com/deepkick/firefox-ios.git',\n",
       "  'ssh_url': 'git@github.com:deepkick/firefox-ios.git',\n",
       "  'clone_url': 'https://github.com/deepkick/firefox-ios.git',\n",
       "  'svn_url': 'https://github.com/deepkick/firefox-ios',\n",
       "  'homepage': '',\n",
       "  'size': 481903,\n",
       "  'stargazers_count': 0,\n",
       "  'watchers_count': 0,\n",
       "  'language': None,\n",
       "  'has_issues': False,\n",
       "  'has_projects': True,\n",
       "  'has_downloads': True,\n",
       "  'has_wiki': True,\n",
       "  'has_pages': False,\n",
       "  'forks_count': 0,\n",
       "  'mirror_url': None,\n",
       "  'archived': False,\n",
       "  'disabled': False,\n",
       "  'open_issues_count': 0,\n",
       "  'license': {'key': 'mpl-2.0',\n",
       "   'name': 'Mozilla Public License 2.0',\n",
       "   'spdx_id': 'MPL-2.0',\n",
       "   'url': 'https://api.github.com/licenses/mpl-2.0',\n",
       "   'node_id': 'MDc6TGljZW5zZTE0'},\n",
       "  'forks': 0,\n",
       "  'open_issues': 0,\n",
       "  'watchers': 0,\n",
       "  'default_branch': 'master'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    import requests, json\n",
    "    \n",
    "    #github_user = \"joelgrus\"\n",
    "    github_user = \"deepkick\"\n",
    "    endpoint = f\"https://api.github.com/users/{github_user}/repos\"\n",
    "    \n",
    "    repos = json.loads(requests.get(endpoint).text)\n",
    "    \n",
    "    from collections import Counter\n",
    "    from dateutil.parser import parse\n",
    "    \n",
    "    dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "    month_counts = Counter(date.month for date in dates)\n",
    "    weekday_counts = Counter(date.weekday() for date in dates)\n",
    "    \n",
    "    last_5_repositories = sorted(repos,\n",
    "                                 key=lambda r: r[\"pushed_at\"],\n",
    "                                 reverse=True)[:5]\n",
    "    \n",
    "    last_5_languages = [repo[\"language\"]\n",
    "                        for repo in last_5_repositories]\n",
    "    \n",
    "    last_5_repositories\n",
    "    \n",
    "    #last_5_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "874\n",
      "437\n",
      "{'https://jayapal.house.gov/category/press-releases/'}\n",
      "after sampling, left with ['https://chuygarcia.house.gov/', 'https://himes.house.gov/', 'https://mccollum.house.gov', 'https://norton.house.gov/', 'https://dennyheck.house.gov']\n",
      "https://chuygarcia.house.gov/: {'/media/press-releases'}\n",
      "https://himes.house.gov/: set()\n",
      "https://mccollum.house.gov: {'/media/press-releases'}\n",
      "https://norton.house.gov/: {'/media-center/press-releases'}\n",
      "https://dennyheck.house.gov: {'/media-center/press-releases'}\n"
     ]
    },
    {
     "ename": "TwythonError",
     "evalue": "Twitter API returned a 400 (Bad Request), b'{\"errors\":[{\"code\":215,\"message\":\"Bad Authentication data.\"}]}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTwythonError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a186faefefa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# stream.statuses.sample()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a186faefefa9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Get a temporary client to retrieve an authentication url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mtemp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONSUMER_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONSUMER_SECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mtemp_creds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_authentication_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_creds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auth_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/py37_Kaggle/lib/python3.7/site-packages/twython/api.py\u001b[0m in \u001b[0;36mget_authentication_tokens\u001b[0;34m(self, callback_url, force_login, screen_name)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise TwythonError(response.content,\n\u001b[0;32m--> 339\u001b[0;31m                                error_code=response.status_code)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mrequest_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_qsl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTwythonError\u001b[0m: Twitter API returned a 400 (Bad Request), b'{\"errors\":[{\"code\":215,\"message\":\"Bad Authentication data.\"}]}'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    url = \"https://www.house.gov/representatives\"\n",
    "    text = requests.get(url).text\n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "    \n",
    "    all_urls = [a['href']\n",
    "                for a in soup('a')\n",
    "                if a.has_attr('href')]\n",
    "    \n",
    "    print(len(all_urls))  # 965 for me, way too many\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    # Must start with http:// or https://\n",
    "    # Must end with .house.gov or .house.gov/\n",
    "    regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
    "    \n",
    "    # Let's write some tests!\n",
    "    assert re.match(regex, \"http://joel.house.gov\")\n",
    "    assert re.match(regex, \"https://joel.house.gov\")\n",
    "    assert re.match(regex, \"http://joel.house.gov/\")\n",
    "    assert re.match(regex, \"https://joel.house.gov/\")\n",
    "    assert not re.match(regex, \"joel.house.gov\")\n",
    "    assert not re.match(regex, \"http://joel.house.com\")\n",
    "    assert not re.match(regex, \"https://joel.house.gov/biography\")\n",
    "    \n",
    "    # And now apply\n",
    "    good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "    \n",
    "    print(len(good_urls))  # still 862 for me\n",
    "    \n",
    "    \n",
    "    num_original_good_urls = len(good_urls)\n",
    "    \n",
    "    good_urls = list(set(good_urls))\n",
    "    \n",
    "    print(len(good_urls))  # only 431 for me\n",
    "    \n",
    "    \n",
    "    assert len(good_urls) < num_original_good_urls\n",
    "    \n",
    "    html = requests.get('https://jayapal.house.gov').text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    \n",
    "    # Use a set because the links might appear multiple times.\n",
    "    links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "    \n",
    "    print(links) # {'/media/press-releases'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # I don't want this file to scrape all 400+ websites every time it runs.\n",
    "    # So I'm going to randomly throw out most of the urls.\n",
    "    # The code in the book doesn't do this.\n",
    "    import random\n",
    "    good_urls = random.sample(good_urls, 5)\n",
    "    print(f\"after sampling, left with {good_urls}\")\n",
    "    \n",
    "    from typing import Dict, Set\n",
    "    \n",
    "    press_releases: Dict[str, Set[str]] = {}\n",
    "    \n",
    "    for house_url in good_urls:\n",
    "        html = requests.get(house_url).text\n",
    "        soup = BeautifulSoup(html, 'html5lib')\n",
    "        pr_links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "        print(f\"{house_url}: {pr_links}\")\n",
    "        press_releases[house_url] = pr_links\n",
    "    \n",
    "    for house_url, pr_links in press_releases.items():\n",
    "        for pr_link in pr_links:\n",
    "            url = f\"{house_url}/{pr_link}\"\n",
    "            text = requests.get(url).text\n",
    "    \n",
    "            if paragraph_mentions(text, 'data'):\n",
    "                print(f\"{house_url}\")\n",
    "                break  # done with this house_url\n",
    "    \n",
    "    import requests, json\n",
    "    \n",
    "    github_user = \"joelgrus\"\n",
    "    endpoint = f\"https://api.github.com/users/{github_user}/repos\"\n",
    "    \n",
    "    repos = json.loads(requests.get(endpoint).text)\n",
    "    \n",
    "    from collections import Counter\n",
    "    from dateutil.parser import parse\n",
    "    \n",
    "    dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "    month_counts = Counter(date.month for date in dates)\n",
    "    weekday_counts = Counter(date.weekday() for date in dates)\n",
    "    \n",
    "    last_5_repositories = sorted(repos,\n",
    "                                 key=lambda r: r[\"pushed_at\"],\n",
    "                                 reverse=True)[:5]\n",
    "    \n",
    "    last_5_languages = [repo[\"language\"]\n",
    "                        for repo in last_5_repositories]\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Feel free to plug your key and secret in directly\n",
    "    CONSUMER_KEY = os.environ.get(\"TWITTER_CONSUMER_KEY\")\n",
    "    CONSUMER_SECRET = os.environ.get(\"TWITTER_CONSUMER_SECRET\")\n",
    "    \n",
    "    import webbrowser\n",
    "    from twython import Twython\n",
    "    \n",
    "    # Get a temporary client to retrieve an authentication url\n",
    "    temp_client = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    temp_creds = temp_client.get_authentication_tokens()\n",
    "    url = temp_creds['auth_url']\n",
    "    \n",
    "    # Now visit that URL to authorize the application and get a PIN\n",
    "    print(f\"go visit {url} and get the PIN code and paste it below\")\n",
    "    webbrowser.open(url)\n",
    "    PIN_CODE = input(\"please enter the PIN code: \")\n",
    "    \n",
    "    # Now we use that PIN_CODE to get the actual tokens\n",
    "    auth_client = Twython(CONSUMER_KEY,\n",
    "                          CONSUMER_SECRET,\n",
    "                          temp_creds['oauth_token'],\n",
    "                          temp_creds['oauth_token_secret'])\n",
    "    final_step = auth_client.get_authorized_tokens(PIN_CODE)\n",
    "    ACCESS_TOKEN = final_step['oauth_token']\n",
    "    ACCESS_TOKEN_SECRET = final_step['oauth_token_secret']\n",
    "    \n",
    "    # And get a new Twython instance using them.\n",
    "    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    \n",
    "    from twython import TwythonStreamer\n",
    "    \n",
    "    # Appending data to a global variable is pretty poor form\n",
    "    # but it makes the example much simpler\n",
    "    tweets = []\n",
    "    \n",
    "    class MyStreamer(TwythonStreamer):\n",
    "        def on_success(self, data):\n",
    "            \"\"\"\n",
    "            What do we do when twitter sends us data?\n",
    "            Here data will be a Python dict representing a tweet\n",
    "            \"\"\"\n",
    "            # We only want to collect English-language tweets\n",
    "            if data.get('lang') == 'en':\n",
    "                tweets.append(data)\n",
    "                print(f\"received tweet #{len(tweets)}\")\n",
    "    \n",
    "            # Stop when we've collected enough\n",
    "            if len(tweets) >= 100:\n",
    "                self.disconnect()\n",
    "    \n",
    "        def on_error(self, status_code, data):\n",
    "            print(status_code, data)\n",
    "            self.disconnect()\n",
    "    \n",
    "    stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET,\n",
    "                        ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    \n",
    "    # starts consuming public statuses that contain the keyword 'data'\n",
    "    stream.statuses.filter(track='data')\n",
    "    \n",
    "    # if instead we wanted to start consuming a sample of *all* public statuses\n",
    "    # stream.statuses.sample()\n",
    "    \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
